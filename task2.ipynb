{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 2\n",
    "Previsione delle stelle delle recensioni sulla base del testo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.initializers import Constant\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm\n",
    "from official.nlp import optimization\n",
    "\n",
    "from libraries.dataset import Dataset\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "import tensorflow_text\n",
    "import keras_tuner as kt\n",
    "\n",
    "import libraries.preprocessing_utils as prep_utils\n",
    "import libraries.models_builders as models_builders\n",
    "import libraries.filenames_generator as filenames  \n",
    "import constants as const\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "print(tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data retrieving\n",
    "Ottenimento dei dati relativi alle recensioni, bilanciati sulla base delle stelle, al fine di ottenere lo stesso numero di review per ogni possibile valutazione (da 1 a 5).\n",
    "In questo specifico caso, sono richiesti 20'000 campioni per ogni tipo di classe (per un totale di 100'000 campioni).\n",
    "\n",
    "L'oggetto `review_data` contiene tre field relativi ai subdataset da utilizzare nel progetto:\n",
    "- `train_data` = tupla contentente i dati ed i target per il training\n",
    "- `val_data` = tupla contentente i dati ed i target per la validazione\n",
    "- `test_data` = tupla contentente i dati ed i target per il testing\n",
    "\n",
    "Alla prima esecuzione, i tre diversi subset sono memorizzati sottoforma di file csv, in modo da evitare la riesecuzione del codice di splitting dei dataset durante le successive esecuzioni.   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_data = Dataset('review', 'stars')\n",
    "\n",
    "review_data.split(['text'], 'stars', n_samples=20_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing comune\n",
    "\n",
    "Fase di preparazione dei dati grezzi caricati precedentemente, al fine di ottenere testo pulito utilizzabile come base per i diversi modelli di machine learning da testare.\n",
    "\n",
    "Le azioni di preprocessing attuate in questa fase sono:\n",
    "  - riduzione testo dal maiuscolo al *minuscolo*\n",
    "  - *decontrazione* forme contratte\n",
    "  - rimozione delle stop-words\n",
    "  - lemmatizzazione\n",
    "\n",
    "Ogni modello aggiungerà successivamente ulteriori azioni di processamento dei dati, necessarie per adattarli al meglio al tipo di input atteso.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_train_data = prep_utils.preprocess_texts(review_data.train_data[0]['text'], path= filenames.picked_cleaned_sentences(\n",
    "        \"train\", \"task2\"))\n",
    "\n",
    "prep_test_data = prep_utils.preprocess_texts(review_data.test_data[0]['text'], path= filenames.picked_cleaned_sentences(\n",
    "        \"test\", \"task2\"))\n",
    "\n",
    "prep_val_data = prep_utils.preprocess_texts(review_data.val_data[0]['text'], path= filenames.picked_cleaned_sentences(\n",
    "        \"val\", \"task2\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training dei classificatori\n",
    "Fase di addestramento dei classificatori.\n",
    "\n",
    "I classificatori testati sono:\n",
    "- **Multinomial Naive Bayes**\n",
    "- **KNN**\n",
    "- **SVM**\n",
    "- **LSTM**\n",
    "- **BERT**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes\n",
    "\n",
    "Addestramento del classificatore di tipo Multinomial Naive Baye su un subset ridotto di 30'000 campioni.\n",
    "\n",
    "E' stata applicata ai dati un'azione aggiuntiva di preprocessing, eseguita dall'oggetto `CountVectorizer`, il quale converte la collezione dei testi delle recensioni in una matrice contenente il conteggio dei token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_train_df = pd.DataFrame({'text': prep_train_data, 'stars': review_data.train_data[1]})\n",
    "s1 = sub_train_df.loc[sub_train_df['stars'] == 1].iloc[:6000, :]\n",
    "s2 = sub_train_df.loc[sub_train_df['stars'] == 2].iloc[:6000, :]\n",
    "s3 = sub_train_df.loc[sub_train_df['stars'] == 3].iloc[:6000, :]\n",
    "s4 = sub_train_df.loc[sub_train_df['stars'] == 4].iloc[:6000, :]\n",
    "s5 = sub_train_df.loc[sub_train_df['stars'] == 5].iloc[:6000, :]\n",
    "\n",
    "sub_train_df = pd.concat([s1, s2, s3, s4, s5], ignore_index=True)\n",
    "sub_train_df = sub_train_df.sample(frac=1, random_state=const.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "nb_train_data = vectorizer.fit_transform(sub_train_df['text']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(nb_train_data, sub_train_df['stars'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nella fase di testing del modello addestrato, l'accuratezza raggiunta è stata del 51.6% sul test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.516"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_test_data = vectorizer.transform(prep_test_data[:10000]).toarray()\n",
    "nb_model.score(nb_test_data, review_data.test_data[1][:10000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN\n",
    "\n",
    "Addestramento del classificatore di tipo KNN su un subset ridotto di 30'000 campioni.\n",
    "\n",
    "Sono stati utilizzati gli stessi input processati per il modello Naive Bayes precedente ed il miglior modello è stato ricercato eseguendo diverse prove con valori per il numero di vicini.\n",
    "\n",
    "L'accuratezza raggiunta nella fase di testing del modello è stata del 35.3% ed il valore di *k* che ha permesso di raggiungere tale percentuale è stato di 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = GridSearchCV(KNeighborsClassifier(), param_grid={\"n_neighbors\": [2,4,10,15,25,50,100,200,400]})\n",
    "cv.fit(nb_train_data, sub_train_df['stars'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.353\n",
      "{'n_neighbors': 50}\n"
     ]
    }
   ],
   "source": [
    "nb_test_data = vectorizer.transform(prep_test_data[:10000]).toarray()\n",
    "print(cv.score(nb_test_data, review_data.test_data[1][:10000]))\n",
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM\n",
    "Addestramento del classificatore di tipo SVM su un subset ridotto di 2'000 campioni.\n",
    "\n",
    "E' stata applicata ai dati un'azione aggiuntiva di preprocessing, eseguita dall'oggetto `CountVectorizer` e sono state testate diverse architetture con valori del parametro C differenti.\n",
    "\n",
    "L'accuratezza raggiunta nella fase di testing del modello è stata del 43.4% ed il valore di C che ha permesso di raggiungere tale percentuale è pari a 1 con l'utilizzo di un kernel lineare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_train_df = pd.DataFrame({'text': prep_train_data, 'stars': review_data.train_data[1]})\n",
    "s1 = sub_train_df.loc[sub_train_df['stars'] == 1].iloc[:400, :]\n",
    "s2 = sub_train_df.loc[sub_train_df['stars'] == 2].iloc[:400, :]\n",
    "s3 = sub_train_df.loc[sub_train_df['stars'] == 3].iloc[:400, :]\n",
    "s4 = sub_train_df.loc[sub_train_df['stars'] == 4].iloc[:400, :]\n",
    "s5 = sub_train_df.loc[sub_train_df['stars'] == 5].iloc[:400, :]\n",
    "\n",
    "sub_train_df = pd.concat([s1, s2, s3, s4, s5], ignore_index=True)\n",
    "sub_train_df = sub_train_df.sample(frac=1, random_state=const.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_train_data = vectorizer.fit_transform(sub_train_df['text']).toarray()\n",
    "cv = GridSearchCV(svm.SVC(), param_grid={\"kernel\": ['linear'],\"C\": [1,2,4,10,15,25,50,100,200,400]})\n",
    "cv.fit(svm_train_data, sub_train_df['stars'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_test_data = vectorizer.transform(prep_test_data[:750]).toarray()\n",
    "print(cv.score(svm_test_data, review_data.test_data[1][:750]))\n",
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM\n",
    "Al fine di trovare la combinazione di iperparametri che rendono le migliori performance, sono state testate diverse architetture delle **Reti neurali ricorrenti** di tipo **LSTM**.\n",
    "\n",
    "Anche in questo caso è stato effettuato un preprocessing aggiuntivo sui testi delle recensioni (i quali fungono come input alle reti).\n",
    "Tale attività è stata eseguita da un *tokenizer* specifico, il quale restituisce, per ogni recensione, un vettore contenente gli indici delle parole in essa contenute.\n",
    "\n",
    "Tali indici sono relativi alla posizione delle parole nel dizionario estratto precedemente dalla collezione di recensioni e sono fondamentali per il recupero delle word embedding corrispondenti alle parole, come avviene nel layer di tipo **Embedding** impostato come primo layer della rete LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = prep_utils.get_tokenizer(review_data.train_data[0]['text'])\n",
    "\n",
    "train_tokens = prep_utils.get_set_tokens(\n",
    "    review_data.train_data[0]['text'], tokenizer, set='train', task='task2')\n",
    "\n",
    "test_tokens = prep_utils.get_set_tokens(\n",
    "    review_data.test_data[0]['text'], tokenizer, set='test', task='task2')\n",
    "\n",
    "val_tokens = prep_utils.get_set_tokens(\n",
    "    review_data.val_data[0]['text'], tokenizer, set='val', task='task2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esistono diverse metodologie per la definizione dei **word vectors** e queste spaziano dal training di reti come *Word2Vec* all'utilizzo di mapping già pre-addestrati.\n",
    "\n",
    "Nel caso di questo studio è stato scelto di creare un'embedding matrix a partire da un mapping già esistente, nello specifico quello messo a disposizione da **Glove** e addestrato su una grande mole di dati testuali estratti da *twitter*.\n",
    "\n",
    "Sulla base di questo mapping, sono stati estratti, ed inseriti in una matrice, i vettori delle parole presenti nel dizionario e, se non presenti, queste sono state rappresentate come 0-vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_matrix = prep_utils.get_embedding_matrix(const.word_embedding_filepath, 'task2',\n",
    "                                            tokenizer, len(tokenizer.index_word)+1)\n",
    "\n",
    "word_vector_dim = 100\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) +1\n",
    "max_length = len(max(train_tokens, key=len))\n",
    "\n",
    "embedding_layer = Embedding(vocab_size, word_vector_dim,\n",
    "                            embeddings_initializer=Constant(e_matrix), trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fase di tuning degli iperparametri.\n",
    "\n",
    "La ricerca è stata condotta su un unico trial. Gli iperparametri testati sono:\n",
    "- *numero di unità* (dimensione del vettore delle celle e hidden states)\n",
    "- *percentuale di dropout*\n",
    "- *learning rate*\n",
    "\n",
    "Il training è stato gestito utilizzando la tecnica dell'*early stopping*, dettata dalla seguente callback, la quale termina il training dopo 15 epoche prive di miglioramenti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_early_cb = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = \"task2_lstm_adam_128\"\n",
    "\n",
    "builder = models_builders.get_rnn_builder(\n",
    "    drop=[0.2, 0.5],\n",
    "    units=[15, 20, 50, 80],\n",
    "    lrate=[0.01, 0.001],\n",
    "    optimizer=keras.optimizers.Adam,\n",
    "    embedding_layer=embedding_layer,\n",
    "    output_shape=5,\n",
    "    activation=\"softmax\",\n",
    "    loss=keras.losses.CategoricalCrossentropy())\n",
    "\n",
    "tuner = kt.RandomSearch(\n",
    "    builder,\n",
    "    objective = 'val_accuracy',\n",
    "    max_trials = 10,\n",
    "    directory = const.tuner_path, project_name = project_name\n",
    ")\n",
    "\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(train_tokens, pd.get_dummies(review_data.train_data[1]),\n",
    "             batch_size=128, epochs=1000,\n",
    "             validation_data=(val_tokens, pd.get_dummies(review_data.val_data[1])),\n",
    "             callbacks=[\n",
    "                 stop_early_cb,\n",
    "                 tf.keras.callbacks.TensorBoard(const.logs_path + project_name, update_freq='epoch')],\n",
    "             verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il miglior modello trovato, in seguito all'esecuzione dell'unico trial, fornisce un'accuratezza sul validation set del 60.5% e si presenta come una rete con le seguenti caratteristiche:\n",
    "- dropout del 20%\n",
    "- learning rate di 0.01\n",
    "- 15 units\n",
    "\n",
    "Tutte le statistiche di esecuzione sono visualizzabili su tensorboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT\n",
    "E' stata testata anche la tecnica **BERT**, basata sui transformer.\n",
    "\n",
    "Si è scelto di basarsi sul modello pre-addestrato **Small Bert**, caratterizzato da un numero minore di transformer blocks, e di procedere successivamente con il suo fine-tuning per adattarlo al problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "handle_encoder = 'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1'\n",
    "handle_preprocess = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ricaricamento del dataset e suddivisione in training, validation e test set con percentuali differenti rispetto a prima. In questo caso è stato assegnato l'80% dei campioni al training set ed il restante 20% al validation e testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_data = Dataset('review', 'stars')\n",
    "review_data.split(['text'], 'stars', n_samples=20_000, val_size=0.1, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_train_data = prep_utils.preprocess_texts(review_data.train_data[0]['text'], path= filenames.picked_cleaned_sentences(\n",
    "        \"train\", \"task2\"))\n",
    "\n",
    "prep_test_data = prep_utils.preprocess_texts(review_data.test_data[0]['text'], path= filenames.picked_cleaned_sentences(\n",
    "        \"test\", \"task2\"))\n",
    "\n",
    "prep_val_data = prep_utils.preprocess_texts(review_data.val_data[0]['text'], path= filenames.picked_cleaned_sentences(\n",
    "        \"val\", \"task2\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processamento aggiuntivo dei dati e wrapping dei testi delle recensioni e dei target nell'oggetto `Dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = tf.data.Dataset.from_tensor_slices((prep_train_data, pd.get_dummies(review_data.train_data[1])))\n",
    "val_df = tf.data.Dataset.from_tensor_slices((prep_val_data, pd.get_dummies(review_data.val_data[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creazione del modello."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "\n",
    "steps_per_epoch = tf.data.experimental.cardinality(train_df).numpy()\n",
    "num_train_steps = steps_per_epoch * epochs\n",
    "num_warmup_steps = int(0.1*num_train_steps)\n",
    "\n",
    "init_lr = 3e-5\n",
    "optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
    "                                          num_train_steps=num_train_steps,\n",
    "                                          num_warmup_steps=num_warmup_steps, # lr decay\n",
    "                                          optimizer_type='adamw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models_builders.build_BERT_model(handle_preprocess, handle_encoder, 5, activation=\"softmax\")\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "                loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "                metrics=tf.metrics.CategoricalAccuracy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Addestramento del modello.\n",
    "\n",
    "L'accuratezza raggiunta sul training set è del 62.6% e sul validation set del 59.3%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 16\n",
    "\n",
    "history = model.fit(x=train_df.batch(batch),\n",
    "                    validation_data=val_df.batch(batch),\n",
    "                    epochs=epochs,\n",
    "                    callbacks=[\n",
    "                               tf.keras.callbacks.TensorBoard(const.logs_path + \"bert_task2\", update_freq='epoch')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il modello sul test set ha raggiunto un'accuratezza del 58.8%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 95s 94ms/step - loss: 1.0897 - categorical_accuracy: 0.5880\n"
     ]
    }
   ],
   "source": [
    "test_df = tf.data.Dataset.from_tensor_slices((prep_test_data, pd.get_dummies(review_data.test_data[1])))\n",
    "\n",
    "loss, accuracy = model.evaluate(test_df.batch(1))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "459930712a401b3fdc8e16187022002e211063c53d40f80d6478e75ae7a84c3a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 ('ai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
