{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 2\n",
    "Previsione stelle della recensione sulla base del testo che l'utente scrive "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\miche\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\miche\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\miche\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.initializers import Constant\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm\n",
    "from official.nlp import optimization\n",
    "\n",
    "# from libraries import data_handler\n",
    "from libraries.dataset import Dataset\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "import tensorflow_text\n",
    "import keras_tuner as kt\n",
    "\n",
    "import libraries.preprocessing_utils as prep_utils\n",
    "import libraries.models_builders as models_builders\n",
    "import libraries.filenames_generator as filenames  \n",
    "import constants as const\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "print(tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data retrieving\n",
    "Ottenimento dei dati relativi alle recensioni, bilanciati sulla base delle stelle, al fine di ottenere lo stesso numero di review per ogni possibile valutazione (da 1 a 5).\n",
    "In questo specifico caso, sono richiesti 20'000 campioni per ogni tipo di classe (per un totale di 100'000 campioni).\n",
    "\n",
    "L'oggetto `review_data` contiene tre field relativi ai subdataset da utilizzare nel progetto:\n",
    "- `train_data` = tupla contentente i dati ed i target per il training\n",
    "- `val_data` = tupla contentente i dati ed i target per la validazione\n",
    "- `test_data` = tupla contentente i dati ed i target per il testing\n",
    "\n",
    "Alla prima esecuzione, i tre diversi subset sono memorizzati sottoforma di file csv, in modo da evitare la riesecuzione del codice di splitting dei dataset durante le successive esecuzioni.   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading ./data/balanced_review_stars_train.csv...\n",
      "File loaded in 0.0222 minutes\n",
      "Reading ./data/balanced_review_stars_val.csv...\n",
      "File loaded in 0.001 minutes\n",
      "Reading ./data/balanced_review_stars_test.csv...\n",
      "File loaded in 0.0017 minutes\n"
     ]
    }
   ],
   "source": [
    "review_data = Dataset('review', 'stars')\n",
    "\n",
    "# 20_000 elements for each class\n",
    "review_data.split(['text'], 'stars', n_samples=20_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing comune\n",
    "\n",
    "Fase di preparazione dei dati grezzi caricati precedentemente, al fine di ottenere testo pulito utilizzabile come base per i diversi modelli di machine learning da testare.\n",
    "\n",
    "Le azioni di preprocessing dei dati attuate in questa fase sono:\n",
    "  - riduzione testo dal maiuscolo al *minuscolo*\n",
    "  - *decontrazione* forme contratte\n",
    "  - rimozione delle stop-words\n",
    "  - lemmatizzazione\n",
    "\n",
    "Ogni modello aggiungerà successivamente ulteriori azioni di processamento dei dati, necessarie per adattarli al meglio al tipo di input atteso.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pickled cleaned sentences data from ./data/pickled/task2_train_cleaned_sentences.pkl...\n",
      "Loading pickled cleaned sentences data from ./data/pickled/task2_test_cleaned_sentences.pkl...\n",
      "Loading pickled cleaned sentences data from ./data/pickled/task2_val_cleaned_sentences.pkl...\n"
     ]
    }
   ],
   "source": [
    "prep_train_data = prep_utils.preprocess_texts(review_data.train_data[0]['text'], path= filenames.picked_cleaned_sentences(\n",
    "        \"train\", \"task2\"))\n",
    "\n",
    "prep_test_data = prep_utils.preprocess_texts(review_data.test_data[0]['text'], path= filenames.picked_cleaned_sentences(\n",
    "        \"test\", \"task2\"))\n",
    "\n",
    "prep_val_data = prep_utils.preprocess_texts(review_data.val_data[0]['text'], path= filenames.picked_cleaned_sentences(\n",
    "        \"val\", \"task2\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training dei classificatori\n",
    "Fase di addestramento dei classificatori.\n",
    "\n",
    "I classificatori testati sono:\n",
    "- **Multinomial Naive Bayes**\n",
    "- **KNN**\n",
    "- **SVM**\n",
    "- **LSTM**\n",
    "- **BERT**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes\n",
    "\n",
    "Addestramento del classificatore di tipo Multinomial Naive Baye su un subset ridotto di 30'000 campioni.\n",
    "\n",
    "E' stato applicata ai dati un'azione aggiuntiva di preprocessing, eseguita dall'oggetto `CountVectorizer`, il quale converte la collezione dei testi delle recensioni in una matrice contenente il conteggio dei token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_train_df = pd.DataFrame({'text': prep_train_data, 'stars': review_data.train_data[1]})\n",
    "s1 = sub_train_df.loc[sub_train_df['stars'] == 1].iloc[:6000, :]\n",
    "s2 = sub_train_df.loc[sub_train_df['stars'] == 2].iloc[:6000, :]\n",
    "s3 = sub_train_df.loc[sub_train_df['stars'] == 3].iloc[:6000, :]\n",
    "s4 = sub_train_df.loc[sub_train_df['stars'] == 4].iloc[:6000, :]\n",
    "s5 = sub_train_df.loc[sub_train_df['stars'] == 5].iloc[:6000, :]\n",
    "\n",
    "sub_train_df = pd.concat([s1, s2, s3, s4, s5], ignore_index=True)\n",
    "sub_train_df = sub_train_df.sample(frac=1, random_state=const.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "nb_train_data = vectorizer.fit_transform(sub_train_df['text']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(nb_train_data, sub_train_df['stars'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nella fase di testing del modello addestrato, l'accuratezza raggiunta è stata 51.6%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.516"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_test_data = vectorizer.transform(prep_test_data[:10000]).toarray()\n",
    "nb_model.score(nb_test_data, review_data.test_data[1][:10000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN\n",
    "\n",
    "Addestramento del classificatore di tipo KNN su un subset ridotto di 30'000 campioni.\n",
    "\n",
    "E' stato utilizzato l'oggetto `CountVectorizer` definito in precedenza ed è stato testato su diversi valori di k vicini.\n",
    "L'accuratezza raggiunta nella fase di testing del modello è stata del 35.3% ed il valore di k che ha permesso di raggiungere tale percentuale è stato di 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=KNeighborsClassifier(),\n",
       "             param_grid={'n_neighbors': [2, 4, 10, 15, 25, 50, 100, 200, 400]})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = GridSearchCV(KNeighborsClassifier(), param_grid={\"n_neighbors\": [2,4,10,15,25,50,100,200,400]})\n",
    "cv.fit(nb_train_data, sub_train_df['stars'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.353\n",
      "{'n_neighbors': 50}\n"
     ]
    }
   ],
   "source": [
    "nb_test_data = vectorizer.transform(prep_test_data[:10000]).toarray()\n",
    "print(cv.score(nb_test_data, review_data.test_data[1][:10000]))\n",
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM\n",
    "Addestramento del classificatore di tipo KNN su un subset ridotto di 2'000 campioni.\n",
    "\n",
    "E' stato utilizzato l'oggetto `CountVectorizer` definito in precedenza ed è stato testato su diversi valori di C.\n",
    "L'accuratezza raggiunta nella fase di testing del modello è stata del 43.4% ed il valore di C che ha permesso di raggiungere tale percentuale è pari a 1 con l'utilizzo di un kernel lineare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_train_df = pd.DataFrame({'text': prep_train_data, 'stars': review_data.train_data[1]})\n",
    "s1 = sub_train_df.loc[sub_train_df['stars'] == 1].iloc[:400, :]\n",
    "s2 = sub_train_df.loc[sub_train_df['stars'] == 2].iloc[:400, :]\n",
    "s3 = sub_train_df.loc[sub_train_df['stars'] == 3].iloc[:400, :]\n",
    "s4 = sub_train_df.loc[sub_train_df['stars'] == 4].iloc[:400, :]\n",
    "s5 = sub_train_df.loc[sub_train_df['stars'] == 5].iloc[:400, :]\n",
    "\n",
    "sub_train_df = pd.concat([s1, s2, s3, s4, s5], ignore_index=True)\n",
    "sub_train_df = sub_train_df.sample(frac=1, random_state=const.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_train_data = vectorizer.fit_transform(sub_train_df['text']).toarray()\n",
    "cv = GridSearchCV(svm.SVC(), param_grid={\"kernel\": ['linear'],\"C\": [1,2,4,10,15,25,50,100,200,400]})\n",
    "cv.fit(svm_train_data, sub_train_df['stars'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_test_data = vectorizer.transform(prep_test_data[:750]).toarray()\n",
    "print(cv.score(svm_test_data, review_data.test_data[1][:750]))\n",
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM\n",
    "Al fine di trovare la combinazione di iperparametri che rendono le migliori performance, sono state testate diverse architetture delle **Reti neurali ricorrenti** di tipo **LSTM**.\n",
    "\n",
    "Anche in questo caso è stato effettuato un preprocessing aggiuntivo sui testi delle recensioni (i quali fungono come input alle reti).\n",
    "Tale attività è stata eseguita da un *tokenizer* specifico, il quale restituisce, per ogni recensione, un vettore contenente gli indici delle parole in essa contenute.\n",
    "\n",
    "Tali indici sono relativi alla posizione delle parole nel dizionaio estratto precedemente dalla collezione di recensioni e sono fondamentali per il recupero delle word embedding corrispondenti alle parole, come avviene nel layer di tipo **Embedding** impostato come primo layer della rete LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = prep_utils.get_tokenizer(review_data.train_data[0]['text'])\n",
    "\n",
    "train_tokens = prep_utils.get_set_tokens(\n",
    "    review_data.train_data[0]['text'], tokenizer, set='train', task='task2')\n",
    "\n",
    "test_tokens = prep_utils.get_set_tokens(\n",
    "    review_data.test_data[0]['text'], tokenizer, set='test', task='task2')\n",
    "\n",
    "val_tokens = prep_utils.get_set_tokens(\n",
    "    review_data.val_data[0]['text'], tokenizer, set='val', task='task2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esistono diverse metodologie per la definizione dei **word vectors** e queste spaziano dal training di reti come *Word2Vec* all'utilizzo di mapping già pre-addestrati.\n",
    "\n",
    "Nel caso di questo studio è stato scelto di creare un'embedding matrix a partire da un mapping già esistente, nello specifico quello messo a disposizione da **Glove** e addestrato su una grande mole di dati testuali estratti da *twitter*.\n",
    "\n",
    "Sulla base di questo mapping, sono stati estratti, ed inseriti in una matrice, i vettori delle parole presenti nel dizionario e, se non presenti, queste sono stati rappresentati come 0-vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pickled embedding matrix from ./data/embedding/task2_embedding_matrix.npy...\n",
      "...embedding matrix loaded\n"
     ]
    }
   ],
   "source": [
    "e_matrix = prep_utils.get_embedding_matrix(const.word_embedding_filepath, 'task2',\n",
    "                                            tokenizer, len(tokenizer.index_word)+1)\n",
    "\n",
    "word_vector_dim = 100\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) +1\n",
    "max_length = len(max(train_tokens, key=len))\n",
    "\n",
    "embedding_layer = Embedding(vocab_size, word_vector_dim,\n",
    "                            embeddings_initializer=Constant(e_matrix), trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fase di tuning degli iperparametri.\n",
    "\n",
    "La ricerca è stata condotta su un unico trial. Gli iperparametri testati sono:\n",
    "- *numero di unità* (dimensione del vettore delle celle e hidden states)\n",
    "- *percentuale di dropout*\n",
    "- *learning rate*\n",
    "\n",
    "Il training è stato gestito utilizzando la tecnica dell'*early stopping*, dettata dalla seguente callback, la quale termina il training dopo 15 epoche prive di miglioramenti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define custom callbacks\n",
    "stop_early_cb = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 3\n",
      "dropout (Choice)\n",
      "{'default': 0.2, 'conditions': [], 'values': [0.2, 0.5], 'ordered': True}\n",
      "units (Choice)\n",
      "{'default': 15, 'conditions': [], 'values': [15, 20, 50, 80], 'ordered': True}\n",
      "lr (Choice)\n",
      "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001], 'ordered': True}\n"
     ]
    }
   ],
   "source": [
    "project_name = \"task2_lstm_adam_128\"\n",
    "\n",
    "builder = models_builders.get_rnn_builder(\n",
    "    drop=[0.2, 0.5],\n",
    "    units=[15, 20, 50, 80],\n",
    "    lrate=[0.01, 0.001],\n",
    "    optimizer=keras.optimizers.Adam,\n",
    "    embedding_layer=embedding_layer,\n",
    "    output_shape=5,\n",
    "    activation=\"softmax\",\n",
    "    loss=keras.losses.CategoricalCrossentropy())\n",
    "\n",
    "tuner = kt.RandomSearch(\n",
    "    builder,\n",
    "    objective = 'val_accuracy',\n",
    "    max_trials = 10,\n",
    "    directory = const.tuner_path, project_name = project_name\n",
    ")\n",
    "\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0549s vs `on_train_batch_end` time: 0.0688s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0447s vs `on_train_batch_end` time: 0.0693s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0393s vs `on_train_batch_end` time: 0.0439s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0299s vs `on_train_batch_end` time: 0.0714s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0560s vs `on_train_batch_end` time: 0.0590s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0337s vs `on_train_batch_end` time: 0.0672s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0231s vs `on_train_batch_end` time: 0.0504s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0243s vs `on_train_batch_end` time: 0.0511s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0283s vs `on_train_batch_end` time: 0.0346s). Check your callbacks.\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(train_tokens, pd.get_dummies(review_data.train_data[1]),\n",
    "             batch_size=128, epochs=1000,\n",
    "             validation_data=(val_tokens, pd.get_dummies(review_data.val_data[1])),\n",
    "             callbacks=[\n",
    "                 stop_early_cb,\n",
    "                 tf.keras.callbacks.TensorBoard(const.logs_path + project_name, update_freq='epoch')],\n",
    "             verbose=0)\n",
    "\n",
    "#  executed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il miglior modello trovato, in seguito all'esecuzione dell'unico trial, fornisce un'accuratezza sul validation set del 60.5% e si presenta come una rete con le seguenti caratteristiche:\n",
    "- dropout del 20%\n",
    "- learning rate di 0.01\n",
    "- 15 units\n",
    "\n",
    "Tutte le statistiche di esecuzione sono visualizzabili su tensorboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT\n",
    "E' stata testata anche la tecnica **BERT**, basata sui transformer.\n",
    "\n",
    "Si è scelto di basarsi sul modello pre-addestrato **Small Bert**, caratterizzato da un numero minore di transformer blocks, e di procedere successivamente con il suo fine-tuning per adattarlo al problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "handle_encoder = 'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1'\n",
    "handle_preprocess = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rilettura del dataset e suddivione di questo in training, validation e test set, dove il primo ha l'80% dei campioni del dataset originali, mentre gli ultimi due ne contengono ognuno il 10%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_data = Dataset('review', 'stars')\n",
    "review_data.split(['text'], 'stars', n_samples=20_000, val_size=0.1, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_train_data = prep_utils.preprocess_texts(review_data.train_data[0]['text'], path= filenames.picked_cleaned_sentences(\n",
    "        \"train\", \"task2\"))\n",
    "\n",
    "prep_test_data = prep_utils.preprocess_texts(review_data.test_data[0]['text'], path= filenames.picked_cleaned_sentences(\n",
    "        \"test\", \"task2\"))\n",
    "\n",
    "prep_val_data = prep_utils.preprocess_texts(review_data.val_data[0]['text'], path= filenames.picked_cleaned_sentences(\n",
    "        \"val\", \"task2\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processamento aggiuntivo dei dati e wrapping dei testi delle recensioni e dei target nell'oggetto `Dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = tf.data.Dataset.from_tensor_slices((prep_train_data, pd.get_dummies(review_data.train_data[1])))\n",
    "val_df = tf.data.Dataset.from_tensor_slices((prep_val_data, pd.get_dummies(review_data.val_data[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creazione del modello."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "\n",
    "steps_per_epoch = tf.data.experimental.cardinality(train_df).numpy()\n",
    "num_train_steps = steps_per_epoch * epochs\n",
    "num_warmup_steps = int(0.1*num_train_steps)\n",
    "\n",
    "init_lr = 3e-5\n",
    "optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
    "                                          num_train_steps=num_train_steps,\n",
    "                                          num_warmup_steps=num_warmup_steps, # lr decay\n",
    "                                          optimizer_type='adamw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models_builders.build_BERT_model(handle_preprocess, handle_encoder, 5, activation=\"softmax\")\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "                loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "                metrics=tf.metrics.CategoricalAccuracy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Addestramento del modello.\n",
    "\n",
    "L'accuratezza raggiunta sul training set è del  e sul validation set del . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6125/6125 [==============================] - 2246s 364ms/step - loss: 1.4102 - categorical_accuracy: 0.3752 - val_loss: 1.1320 - val_categorical_accuracy: 0.5145\n",
      "Epoch 2/10\n",
      "6125/6125 [==============================] - 5803s 947ms/step - loss: 1.0801 - categorical_accuracy: 0.5272 - val_loss: 1.0419 - val_categorical_accuracy: 0.5544\n",
      "Epoch 3/10\n",
      "6125/6125 [==============================] - 7781s 1s/step - loss: 1.0030 - categorical_accuracy: 0.5601 - val_loss: 1.0045 - val_categorical_accuracy: 0.5714\n",
      "Epoch 4/10\n",
      "6125/6125 [==============================] - 2236s 365ms/step - loss: 0.9554 - categorical_accuracy: 0.5839 - val_loss: 0.9765 - val_categorical_accuracy: 0.5804\n",
      "Epoch 5/10\n",
      "6125/6125 [==============================] - 1850s 302ms/step - loss: 0.9134 - categorical_accuracy: 0.6037 - val_loss: 0.9756 - val_categorical_accuracy: 0.5954\n",
      "Epoch 6/10\n",
      "6125/6125 [==============================] - 1744s 285ms/step - loss: 0.8690 - categorical_accuracy: 0.6258 - val_loss: 0.9834 - val_categorical_accuracy: 0.5884\n",
      "Epoch 7/10\n",
      "6125/6125 [==============================] - 1739s 284ms/step - loss: 0.8203 - categorical_accuracy: 0.6484 - val_loss: 1.0249 - val_categorical_accuracy: 0.5844\n",
      "Epoch 8/10\n",
      "6125/6125 [==============================] - 1737s 284ms/step - loss: 0.7706 - categorical_accuracy: 0.6737 - val_loss: 1.0560 - val_categorical_accuracy: 0.5754\n",
      "Epoch 9/10\n",
      "6125/6125 [==============================] - 1737s 284ms/step - loss: 0.7108 - categorical_accuracy: 0.7038 - val_loss: 1.1071 - val_categorical_accuracy: 0.5824\n",
      "Epoch 10/10\n",
      "6125/6125 [==============================] - 1739s 284ms/step - loss: 0.6503 - categorical_accuracy: 0.7339 - val_loss: 1.2674 - val_categorical_accuracy: 0.5654\n"
     ]
    }
   ],
   "source": [
    "batch = 16\n",
    "\n",
    "history = model.fit(x=train_df.batch(batch),\n",
    "                    validation_data=val_df.batch(batch),\n",
    "                    epochs=epochs,\n",
    "                    callbacks=[\n",
    "                               tf.keras.callbacks.TensorBoard(const.logs_path + \"bert_task2\", update_freq='epoch')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il modello sul test set ha raggiunto un'accuratezza del ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 24s 22ms/step - loss: 1.9961 - categorical_accuracy: 0.2020\n"
     ]
    }
   ],
   "source": [
    "test_df = tf.data.Dataset.from_tensor_slices((prep_test_data, pd.get_dummies(review_data.test_data[1])))\n",
    "\n",
    "loss, accuracy = model.evaluate(test_df.batch(1))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "459930712a401b3fdc8e16187022002e211063c53d40f80d6478e75ae7a84c3a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 ('ai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
