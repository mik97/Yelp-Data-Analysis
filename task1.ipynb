{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 1\n",
    "Riconoscimento review positiva o negativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.initializers import Constant\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from libraries.dataset import Dataset\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "import libraries.preprocessing_utils as prep_utils\n",
    "import libraries.models_builders as models_builders\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "\n",
    "import constants as const"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data retrieving and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading ./data_100_000/balanced_review_sentiment_train.csv...\n",
      "File loaded in 0.03 minutes\n",
      "Reading ./data_100_000/balanced_review_sentiment_val.csv...\n",
      "File loaded in 0.0 minutes\n",
      "Reading ./data_100_000/balanced_review_sentiment_test.csv...\n",
      "File loaded in 0.0 minutes\n"
     ]
    }
   ],
   "source": [
    "review_data = Dataset('review', 'sentiment')\n",
    "#  50_000 for element\n",
    "review_data.split(['text'], 'sentiment', n_samples=50_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess text -> list[str]\n",
    "# fit tokenizer and tokenize\n",
    "tokenizer = prep_utils.get_tokenizer(review_data.train_data[0]['text'])\n",
    "\n",
    "train_tokens = prep_utils.get_set_tokens(\n",
    "    review_data.train_data[0]['text'], tokenizer, set='train', task='task1')\n",
    "\n",
    "test_tokens = prep_utils.get_set_tokens(\n",
    "    review_data.test_data[0]['text'], tokenizer, set='test', task='task1')\n",
    "\n",
    "val_tokens = prep_utils.get_set_tokens(\n",
    "    review_data.val_data[0]['text'], tokenizer, set='val', task='task1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use another texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pickled cleaned sentences data from ./data_100_000/pickled/task1_train_cleaned_sentences.pkl...\n",
      "Loading pickled cleaned sentences data from ./data_100_000/pickled/task1_test_cleaned_sentences.pkl...\n"
     ]
    }
   ],
   "source": [
    "from libraries import utils\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "prep_train_data = prep_utils.preprocess_texts(review_data.train_data[0]['text'], path= utils.cleaned_sentences_file_name(\n",
    "        \"train\", \"task1\"))[:50_000]\n",
    "\n",
    "prep_test_data = prep_utils.preprocess_texts(review_data.test_data[0]['text'], path= utils.cleaned_sentences_file_name(\n",
    "        \"test\", \"task1\"))\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "nb_train_data = vectorizer.fit_transform(prep_train_data).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(nb_train_data, review_data.train_data[1][:50_000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.849"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_test_data = vectorizer.transform(prep_test_data).toarray()\n",
    "\n",
    "nb_model.score(nb_test_data, review_data.test_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "REVIEW:\n",
      "Being a Chinese, I have been to a fair share of Chinese restaurants all over the lower mainland for dim sum with my family and friends.  By far this place has been the ABSOLUTE WORST one!  The service at this place is absolutely horrendous!  Took forever for the food to come out and they just literally throw it onto your table.  The servers have such bad attitude and treated us with hatred and distaste.  After repeatedly asking for extra sauce, we had to go to their stations to get extra soy sauce ourselves.  Everything turned to self-serve, even refilling our own tea!! The servers would treat their regulars with all smiles but completely ignored my table.  I would absolutely never come back here again!  Would not recommend this place to anyone I know!\n",
      "\n",
      "REAL SENTIMENT: 0.0 \n",
      "PREDICTED SENTIMENT: [0.] - negative\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "res = nb_model.predict(nb_test_data[i].reshape(1, -1))\n",
    "\n",
    "print(f'''\n",
    "REVIEW:\n",
    "{review_data.test_data[0]['text'][i]}\n",
    "\n",
    "REAL SENTIMENT: {review_data.test_data[1][i]} \n",
    "PREDICTED SENTIMENT: {res} - {'positive' if res else 'negative'}''')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN - LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pickled embedding matrix from ./data_100_000/embedding/task1_embedding_matrix.npy...\n",
      "...embedding matrix loaded\n"
     ]
    }
   ],
   "source": [
    "e_matrix = prep_utils.get_embedding_matrix(const.word_embedding_filepath, 'task1',\n",
    "                                            tokenizer, len(tokenizer.index_word)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vector_dim = 100\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) +1\n",
    "max_length = len(max(train_tokens, key=len))\n",
    "\n",
    "embedding_layer = Embedding(vocab_size, word_vector_dim,\n",
    "                            embeddings_initializer=Constant(e_matrix), trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the functions that return the hypermodel with a specific hyperparameters search space.\n",
    "\n",
    "Hyperparameters:\n",
    "- number of units\n",
    "- dropout (yes/no) in order to prevent overfitting\n",
    "- learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE:\n",
    "Cell and Hidden states are vectors which have a specific dimension (units parameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define custom callbacks\n",
    "stop_early_cb = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First hyperparams trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 3\n",
      "dropout (Choice)\n",
      "{'default': 0.2, 'conditions': [], 'values': [0.2, 0.5], 'ordered': True}\n",
      "units (Choice)\n",
      "{'default': 15, 'conditions': [], 'values': [15, 20, 50, 80], 'ordered': True}\n",
      "lr (Choice)\n",
      "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001], 'ordered': True}\n"
     ]
    }
   ],
   "source": [
    "project_name = \"task1_lstm_adam_128\"\n",
    "\n",
    "builder = models_builders.get_rnn_builder(\n",
    "    drop=[0.2, 0.5],\n",
    "    units=[15, 20, 50, 80],\n",
    "    lrate=[0.01, 0.001],\n",
    "    optimizer=keras.optimizers.Adam,\n",
    "    embedding_layer=embedding_layer)\n",
    "\n",
    "tuner = kt.RandomSearch(\n",
    "    builder,\n",
    "    objective = 'val_accuracy',\n",
    "    max_trials = 10,\n",
    "    directory = const.tuner_path, project_name = project_name\n",
    ")\n",
    "\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(train_tokens, review_data.train_data[1],\n",
    "             batch_size=128, epochs=1000,\n",
    "             validation_data=(val_tokens, review_data.val_data[1]),\n",
    "             callbacks=[\n",
    "                 stop_early_cb,\n",
    "                 tf.keras.callbacks.TensorBoard(const.logs_path + project_name, update_freq='epoch')],\n",
    "             verbose=0)\n",
    "\n",
    "#  executed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 3\n",
      "dropout (Choice)\n",
      "{'default': 0.2, 'conditions': [], 'values': [0.2, 0.5], 'ordered': True}\n",
      "units (Choice)\n",
      "{'default': 100, 'conditions': [], 'values': [100, 150], 'ordered': True}\n",
      "lr (Choice)\n",
      "{'default': 0.1, 'conditions': [], 'values': [0.1, 0.01, 0.001], 'ordered': True}\n"
     ]
    }
   ],
   "source": [
    "project_name = \"task1_lstm_adam_64_new\"\n",
    "\n",
    "builder = models_builders.get_rnn_builder(\n",
    "    drop=[0.2, 0.5],\n",
    "    units=[100, 150],\n",
    "    lrate=[0.1, 0.01, 0.001],\n",
    "    optimizer=keras.optimizers.Adam,\n",
    "    embedding_layer=embedding_layer)\n",
    "\n",
    "tuner1 = kt.RandomSearch(\n",
    "    builder,\n",
    "    objective = 'val_accuracy',\n",
    "    max_trials = 10,\n",
    "    directory = const.tuner_path, project_name = \"task1_lstm_adam_64\"\n",
    ")\n",
    "\n",
    "tuner1.search_space_summary()\n",
    "\n",
    "# executed\n",
    "tuner1.search(train_tokens, review_data.train_data[1],\n",
    "             batch_size=64, epochs=1000,\n",
    "             validation_data=(val_tokens, review_data.val_data[1]),\n",
    "             callbacks=[\n",
    "                 stop_early_cb,\n",
    "                 tf.keras.callbacks.TensorBoard(const.logs_path + project_name, update_freq='epoch')],\n",
    "             verbose=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get the optimal hyperparameters from the results\n",
    "# best_hps=tuner.get_best_hyperparameters()[0]\n",
    "\n",
    "# # Build model\n",
    "# h_model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# # Train the hypertuned model\n",
    "# h_model.fit(train_tokens, review_data.train_data[1], epochs=1000, validation_data=(val_tokens, review_data.val_data[1]), callbacks=[stop_early_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model = tuner.get_best_models()[0]\n",
    "\n",
    "# # tuner.results_summary()\n",
    "# best_model.summary()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fb20caab5ee8cc09ab8b75b23426de7ab409d2661b4ee85e5bcb1125eed550bf"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('tf-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
